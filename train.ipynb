{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pssr.data import ImageDataset, PairedImageDataset\n",
    "from pssr.crappifiers import AdditiveGaussian, Poisson, Crappifier\n",
    "from pssr.models import ResUNet\n",
    "from pssr.loss import SSIMLoss\n",
    "from pssr.train import train_paired\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "\n",
    "hr_res = 512\n",
    "lr_scale = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ScalePoisson(Crappifier):\n",
    "#     def __init__(self, downres : int, intensity : float = 1, gain : float = 0):\n",
    "#         self.downres = downres\n",
    "#         self.intensity = intensity\n",
    "#         self.gain = gain\n",
    "\n",
    "#         self.resample = Image.Resampling.BICUBIC\n",
    "        \n",
    "#     def crappify(self, image : np.ndarray):\n",
    "#         image = np.clip(self._interpolate(image, np.random.poisson(image/255*image.max())/image.max()*255) + self.gain, 0, 255)\n",
    "#         return np.asarray(Image.fromarray(image).resize([self.downres]*2, resample=self.resample).resize(image.shape, resample=self.resample))\n",
    "    \n",
    "#     def _interpolate(self, x, y):\n",
    "#         return x * (1 - self.intensity) + y * self.intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "crappifier = Poisson(gain=-10, intensity=1)\n",
    "# crappifier = ScalePoisson(125, 1, -2)\n",
    "dataset = ImageDataset(\"testdata/EM_hr_crop\", hr_res, crappifier=crappifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResUNet(\n",
    "    channels=1,\n",
    "    hidden=[64, 128, 256, 512, 1024],\n",
    "    scale=lr_scale,\n",
    "    depth=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "kwargs = dict(\n",
    "    shuffle = True,\n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"trained/poisson_scale_512_.6_0.070.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixel[12.68], psnr[25.65], ssim[0.636]:  38%|███▊      | 229/608 [02:42<04:29,  1.40it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m optim \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m      4\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(optim, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m losses \u001b[38;5;241m=\u001b[39m train_paired(\n\u001b[1;32m      7\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      8\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m      9\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     10\u001b[0m     loss_fn\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[1;32m     11\u001b[0m     optim\u001b[38;5;241m=\u001b[39moptim,\n\u001b[1;32m     12\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     13\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     14\u001b[0m     scheduler\u001b[38;5;241m=\u001b[39mscheduler,\n\u001b[1;32m     15\u001b[0m     log_frequency\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     16\u001b[0m     dataloader_kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m     17\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/PSSR/pssr/train.py:74\u001b[0m, in \u001b[0;36mtrain_paired\u001b[0;34m(model, dataset, batch_size, loss_fn, optim, epochs, device, scheduler, clamp, log_frequency, dataloader_kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m progress \u001b[38;5;241m=\u001b[39m tqdm(train_dataloader)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (hr, lr) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(progress):\n\u001b[0;32m---> 74\u001b[0m     hr, lr \u001b[38;5;241m=\u001b[39m hr\u001b[38;5;241m.\u001b[39mto(device), lr\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     76\u001b[0m     hr_hat \u001b[38;5;241m=\u001b[39m model(lr)\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clamp:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train on mix=.8 until converges, then same on mix=.6\n",
    "loss_fn = SSIMLoss(mix=.6, ms=True)\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, factor=0.1, patience=3, threshold=5e-3, verbose=True)\n",
    "\n",
    "losses = train_paired(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    loss_fn=loss_fn,\n",
    "    optim=optim,\n",
    "    epochs=10,\n",
    "    device=device,\n",
    "    scheduler=scheduler,\n",
    "    log_frequency=50,\n",
    "    dataloader_kwargs=kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"model_{hr_res}_{losses[-1]:.3f}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"poisson_scale_512_.6_0.075.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
